{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/akash-cs13/MSE_Sem2/blob/main/classification_modeltraining1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "O6gm5sbnLXmU"
      },
      "outputs": [],
      "source": [
        "from google.colab import files\n",
        "import zipfile"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!unzip -o data.zip -d data"
      ],
      "metadata": {
        "id": "80HcH4Z4ZWNQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "!pip install torch torchvision\n",
        "\n",
        "# Import Libraries\n",
        "import torch\n",
        "import torchvision\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torchvision import datasets, transforms, models\n",
        "import os\n",
        "from torch.utils.data import DataLoader, random_split\n",
        "import matplotlib.pyplot as plt\n",
        "import copy\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xGbvW4tdZxVO",
        "outputId": "cecaffe5-99b0-4738-8962-c0dbce634538"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (2.3.0+cu121)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.10/dist-packages (0.18.0+cu121)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch) (3.14.0)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch) (4.12.2)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch) (1.12.1)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch) (3.3)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch) (3.1.4)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch) (2023.6.0)\n",
            "Collecting nvidia-cuda-nvrtc-cu12==12.1.105 (from torch)\n",
            "  Using cached nvidia_cuda_nvrtc_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (23.7 MB)\n",
            "Collecting nvidia-cuda-runtime-cu12==12.1.105 (from torch)\n",
            "  Using cached nvidia_cuda_runtime_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (823 kB)\n",
            "Collecting nvidia-cuda-cupti-cu12==12.1.105 (from torch)\n",
            "  Using cached nvidia_cuda_cupti_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (14.1 MB)\n",
            "Collecting nvidia-cudnn-cu12==8.9.2.26 (from torch)\n",
            "  Using cached nvidia_cudnn_cu12-8.9.2.26-py3-none-manylinux1_x86_64.whl (731.7 MB)\n",
            "Collecting nvidia-cublas-cu12==12.1.3.1 (from torch)\n",
            "  Using cached nvidia_cublas_cu12-12.1.3.1-py3-none-manylinux1_x86_64.whl (410.6 MB)\n",
            "Collecting nvidia-cufft-cu12==11.0.2.54 (from torch)\n",
            "  Using cached nvidia_cufft_cu12-11.0.2.54-py3-none-manylinux1_x86_64.whl (121.6 MB)\n",
            "Collecting nvidia-curand-cu12==10.3.2.106 (from torch)\n",
            "  Using cached nvidia_curand_cu12-10.3.2.106-py3-none-manylinux1_x86_64.whl (56.5 MB)\n",
            "Collecting nvidia-cusolver-cu12==11.4.5.107 (from torch)\n",
            "  Using cached nvidia_cusolver_cu12-11.4.5.107-py3-none-manylinux1_x86_64.whl (124.2 MB)\n",
            "Collecting nvidia-cusparse-cu12==12.1.0.106 (from torch)\n",
            "  Using cached nvidia_cusparse_cu12-12.1.0.106-py3-none-manylinux1_x86_64.whl (196.0 MB)\n",
            "Collecting nvidia-nccl-cu12==2.20.5 (from torch)\n",
            "  Using cached nvidia_nccl_cu12-2.20.5-py3-none-manylinux2014_x86_64.whl (176.2 MB)\n",
            "Collecting nvidia-nvtx-cu12==12.1.105 (from torch)\n",
            "  Using cached nvidia_nvtx_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (99 kB)\n",
            "Requirement already satisfied: triton==2.3.0 in /usr/local/lib/python3.10/dist-packages (from torch) (2.3.0)\n",
            "Collecting nvidia-nvjitlink-cu12 (from nvidia-cusolver-cu12==11.4.5.107->torch)\n",
            "  Downloading nvidia_nvjitlink_cu12-12.5.40-py3-none-manylinux2014_x86_64.whl (21.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.3/21.3 MB\u001b[0m \u001b[31m43.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from torchvision) (1.25.2)\n",
            "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.10/dist-packages (from torchvision) (9.4.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch) (2.1.5)\n",
            "Requirement already satisfied: mpmath<1.4.0,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy->torch) (1.3.0)\n",
            "Installing collected packages: nvidia-nvtx-cu12, nvidia-nvjitlink-cu12, nvidia-nccl-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, nvidia-cusparse-cu12, nvidia-cudnn-cu12, nvidia-cusolver-cu12\n",
            "Successfully installed nvidia-cublas-cu12-12.1.3.1 nvidia-cuda-cupti-cu12-12.1.105 nvidia-cuda-nvrtc-cu12-12.1.105 nvidia-cuda-runtime-cu12-12.1.105 nvidia-cudnn-cu12-8.9.2.26 nvidia-cufft-cu12-11.0.2.54 nvidia-curand-cu12-10.3.2.106 nvidia-cusolver-cu12-11.4.5.107 nvidia-cusparse-cu12-12.1.0.106 nvidia-nccl-cu12-2.20.5 nvidia-nvjitlink-cu12-12.5.40 nvidia-nvtx-cu12-12.1.105\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "data_transforms = {\n",
        "    'train': transforms.Compose([\n",
        "        transforms.ColorJitter(0.2, 0.2, 0.2, 0.2),\n",
        "        transforms.RandomHorizontalFlip(),\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
        "    ]),\n",
        "\n",
        "    'val': transforms.Compose([\n",
        "        transforms.ColorJitter(0.2, 0.2, 0.2, 0.2),\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
        "    ]),\n",
        "}"
      ],
      "metadata": {
        "id": "uUQB29iHakZj"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "def create_datasets(data_dir, transform, val_split=0.2):\n",
        "    full_dataset = datasets.ImageFolder(data_dir, transform)\n",
        "    dataset_size = len(full_dataset)\n",
        "    val_size = int(dataset_size * val_split)\n",
        "    train_size = dataset_size - val_size\n",
        "    train_dataset, val_dataset = random_split(full_dataset, [train_size, val_size])\n",
        "    return train_dataset, val_dataset\n"
      ],
      "metadata": {
        "id": "jlev7fCkary9"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create datasets\n",
        "data_dir = 'data'\n",
        "train_dataset, val_dataset = create_datasets(data_dir, data_transforms['train'], val_split=0.2)\n"
      ],
      "metadata": {
        "id": "5qRPZw38cJ4l"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create dataloaders\n",
        "dataloaders = {\n",
        "    'train': DataLoader(train_dataset, batch_size=32, shuffle=True, num_workers=4),\n",
        "    'val': DataLoader(val_dataset, batch_size=32, shuffle=True, num_workers=4)\n",
        "}\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AOtYZrDccRDh",
        "outputId": "c9c5522e-3533-40bd-a970-5ae3459bc6c5"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:558: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(_create_warning_msg(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dataset_sizes = {\n",
        "    'train': len(train_dataset),\n",
        "    'val': len(val_dataset)\n",
        "}\n",
        "\n",
        "class_names = train_dataset.dataset.classes\n",
        "\n",
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n"
      ],
      "metadata": {
        "id": "BIsMUQLocZC1"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the Model\n",
        "def train_model(model, criterion, optimizer, scheduler, num_epochs=10):\n",
        "    best_model_wts = copy.deepcopy(model.state_dict())\n",
        "    best_acc = 0.0\n",
        "\n",
        "    for epoch in range(num_epochs):\n",
        "        print('Epoch {}/{}'.format(epoch+1, num_epochs))\n",
        "        print('-' * 10)\n",
        "\n",
        "        for phase in ['train', 'val']:\n",
        "            if phase == 'train':\n",
        "                model.train()\n",
        "            else:\n",
        "                model.eval()\n",
        "\n",
        "            running_loss = 0.0\n",
        "            running_corrects = 0\n",
        "\n",
        "            for inputs, labels in dataloaders[phase]:\n",
        "                inputs = inputs.to(device)\n",
        "                labels = labels.to(device)\n",
        "\n",
        "                optimizer.zero_grad()\n",
        "\n",
        "                with torch.set_grad_enabled(phase == 'train'):\n",
        "                    outputs = model(inputs)\n",
        "                    _, preds = torch.max(outputs, 1)\n",
        "                    loss = criterion(outputs, labels)\n",
        "\n",
        "                    if phase == 'train':\n",
        "                        loss.backward()\n",
        "                        optimizer.step()\n",
        "\n",
        "                running_loss += loss.item() * inputs.size(0)\n",
        "                running_corrects += torch.sum(preds == labels.data)\n",
        "\n",
        "            if phase == 'train':\n",
        "                scheduler.step()\n",
        "\n",
        "            epoch_loss = running_loss / dataset_sizes[phase]\n",
        "            epoch_acc = running_corrects.double() / dataset_sizes[phase]\n",
        "\n",
        "            print('{} Loss: {:.4f} Acc: {:.4f}'.format(phase, epoch_loss, epoch_acc))\n",
        "\n",
        "            if phase == 'val' and epoch_acc > best_acc:\n",
        "                best_acc = epoch_acc\n",
        "                best_model_wts = copy.deepcopy(model.state_dict())\n",
        "\n",
        "        print()\n",
        "\n",
        "    print('Best val Acc: {:4f}'.format(best_acc))\n",
        "\n",
        "    model.load_state_dict(best_model_wts)\n",
        "    return model\n",
        "\n"
      ],
      "metadata": {
        "id": "FDevhWMAcfnV"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Train ResNet18\n",
        "resnet18 = models.resnet18(pretrained=True)\n",
        "num_ftrs = resnet18.fc.in_features\n",
        "resnet18.fc = nn.Linear(num_ftrs, len(class_names))\n",
        "resnet18 = resnet18.to(device)\n",
        "\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer_resnet = optim.SGD(resnet18.parameters(), lr=0.001, momentum=0.9)\n",
        "exp_lr_scheduler = optim.lr_scheduler.StepLR(optimizer_resnet, step_size=7, gamma=0.1)\n",
        "\n",
        "resnet18 = train_model(resnet18, criterion, optimizer_resnet, exp_lr_scheduler, num_epochs=10)\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OUmHsBKwcyJh",
        "outputId": "424cecad-1b6c-4e2f-9c2d-27a614c281bf"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "----------\n",
            "train Loss: 0.6512 Acc: 0.6700\n",
            "val Loss: 0.4866 Acc: 0.8267\n",
            "\n",
            "Epoch 2/10\n",
            "----------\n",
            "train Loss: 0.3784 Acc: 0.8812\n",
            "val Loss: 0.2581 Acc: 0.9333\n",
            "\n",
            "Epoch 3/10\n",
            "----------\n",
            "train Loss: 0.2264 Acc: 0.9274\n",
            "val Loss: 0.1760 Acc: 0.9333\n",
            "\n",
            "Epoch 4/10\n",
            "----------\n",
            "train Loss: 0.1410 Acc: 0.9505\n",
            "val Loss: 0.1542 Acc: 0.9600\n",
            "\n",
            "Epoch 5/10\n",
            "----------\n",
            "train Loss: 0.1233 Acc: 0.9472\n",
            "val Loss: 0.0954 Acc: 0.9733\n",
            "\n",
            "Epoch 6/10\n",
            "----------\n",
            "train Loss: 0.1228 Acc: 0.9571\n",
            "val Loss: 0.0976 Acc: 0.9600\n",
            "\n",
            "Epoch 7/10\n",
            "----------\n",
            "train Loss: 0.0640 Acc: 0.9835\n",
            "val Loss: 0.0861 Acc: 0.9733\n",
            "\n",
            "Epoch 8/10\n",
            "----------\n",
            "train Loss: 0.0660 Acc: 0.9835\n",
            "val Loss: 0.0546 Acc: 1.0000\n",
            "\n",
            "Epoch 9/10\n",
            "----------\n",
            "train Loss: 0.0600 Acc: 0.9868\n",
            "val Loss: 0.0767 Acc: 0.9867\n",
            "\n",
            "Epoch 10/10\n",
            "----------\n",
            "train Loss: 0.0581 Acc: 0.9868\n",
            "val Loss: 0.0693 Acc: 1.0000\n",
            "\n",
            "Best val Acc: 1.000000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Train MobileNetV3\n",
        "mobilenet_v3 = models.mobilenet_v3_large(pretrained=True)\n",
        "num_ftrs = mobilenet_v3.classifier[3].in_features\n",
        "mobilenet_v3.classifier[3] = nn.Linear(num_ftrs, len(class_names))\n",
        "mobilenet_v3 = mobilenet_v3.to(device)\n",
        "\n",
        "optimizer_mobilenet = optim.SGD(mobilenet_v3.parameters(), lr=0.001, momentum=0.9)\n",
        "exp_lr_scheduler = optim.lr_scheduler.StepLR(optimizer_mobilenet, step_size=7, gamma=0.1)\n",
        "\n",
        "mobilenet_v3 = train_model(mobilenet_v3, criterion, optimizer_mobilenet, exp_lr_scheduler, num_epochs=10)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1ecSCoFuf4Bq",
        "outputId": "aac80a45-7988-436a-a942-0d364e3e74f3"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=MobileNet_V3_Large_Weights.IMAGENET1K_V1`. You can also use `weights=MobileNet_V3_Large_Weights.DEFAULT` to get the most up-to-date weights.\n",
            "  warnings.warn(msg)\n",
            "Downloading: \"https://download.pytorch.org/models/mobilenet_v3_large-8738ca79.pth\" to /root/.cache/torch/hub/checkpoints/mobilenet_v3_large-8738ca79.pth\n",
            "100%|██████████| 21.1M/21.1M [00:00<00:00, 115MB/s] \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "----------\n",
            "train Loss: 0.6579 Acc: 0.6073\n",
            "val Loss: 0.7278 Acc: 0.4800\n",
            "\n",
            "Epoch 2/10\n",
            "----------\n",
            "train Loss: 0.5492 Acc: 0.7921\n",
            "val Loss: 0.6051 Acc: 0.7600\n",
            "\n",
            "Epoch 3/10\n",
            "----------\n",
            "train Loss: 0.4426 Acc: 0.8614\n",
            "val Loss: 0.4936 Acc: 0.8400\n",
            "\n",
            "Epoch 4/10\n",
            "----------\n",
            "train Loss: 0.3671 Acc: 0.8845\n",
            "val Loss: 0.4190 Acc: 0.9200\n",
            "\n",
            "Epoch 5/10\n",
            "----------\n",
            "train Loss: 0.2864 Acc: 0.9241\n",
            "val Loss: 0.3624 Acc: 0.9333\n",
            "\n",
            "Epoch 6/10\n",
            "----------\n",
            "train Loss: 0.2620 Acc: 0.9340\n",
            "val Loss: 0.2563 Acc: 0.9333\n",
            "\n",
            "Epoch 7/10\n",
            "----------\n",
            "train Loss: 0.2045 Acc: 0.9505\n",
            "val Loss: 0.2347 Acc: 0.9200\n",
            "\n",
            "Epoch 8/10\n",
            "----------\n",
            "train Loss: 0.2014 Acc: 0.9373\n",
            "val Loss: 0.2384 Acc: 0.9067\n",
            "\n",
            "Epoch 9/10\n",
            "----------\n",
            "train Loss: 0.2064 Acc: 0.9340\n",
            "val Loss: 0.2513 Acc: 0.8933\n",
            "\n",
            "Epoch 10/10\n",
            "----------\n",
            "train Loss: 0.1887 Acc: 0.9604\n",
            "val Loss: 0.2126 Acc: 0.9467\n",
            "\n",
            "Best val Acc: 0.946667\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Save the Models\n",
        "torch.save(resnet18.state_dict(), 'my_flower_resnet18.pth')\n",
        "torch.save(mobilenet_v3.state_dict(), 'my_flower_mobilenet_v3.pth')\n"
      ],
      "metadata": {
        "id": "euo-mYCqi3Ag"
      },
      "execution_count": 18,
      "outputs": []
    }
  ]
}